{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Activation, Flatten, Dropout, Dense, Embedding, TimeDistributed\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 361\n",
      "Trainable params: 361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15 samples\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5])/10\n",
    "y = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])/10\n",
    "LSTM_layer_num = 4 # number of LSTM layers\n",
    "layer_size = [10,10,10,10] # number of nodes in each layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(layer_size[0], input_dim = 1, activation = \"softmax\"))\n",
    "for i in range(1,LSTM_layer_num) :\n",
    "    model.add(Dense(layer_size[i], activation = \"softmax\"))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "model.compile(loss = 'mse', optimizer = 'adam',\n",
    "            metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model_params = {'epochs':30,\n",
    "                'validation_split':0.2,\n",
    "                'validation_data':None}\n",
    "model.fit(X, y, epochs = model_params['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"carol_data.csv\")\n",
    "data = data.drop(\"Unnamed: 0\", axis = 1)\n",
    "all_text = \"\"\n",
    "for i in range(len(data['song_lyrics'])):\n",
    "    data['song_titles'][i] = data['song_titles'][i].lower()\n",
    "    data['song_lyrics'][i] = data['song_lyrics'][i].lower()\n",
    "    all_text += data['song_lyrics'][i] + '\\n'\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping chars to ints :\n",
    "chars = sorted(list(set(all_text)))\n",
    "int_chars = dict((i, c) for i, c in enumerate(chars))\n",
    "chars_int = dict((i, c) for c, i in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = len(all_text)\n",
    "n_vocab = len(chars)\n",
    "print('Total Characters :' , n_chars) # number of all the characters in lyricsText.txt\n",
    "print('Total Vocab :', n_vocab) # number of unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the dataset:\n",
    "seq_len = 100\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "for i in range(0, n_chars - seq_len, 1):\n",
    "    # Input Sequeance(will be used as samples)\n",
    "    seq_in  = all_text[i:i+seq_len]\n",
    "    # Output sequence (will be used as target)\n",
    "    seq_out = all_text[i + seq_len]\n",
    "    # Store samples in data_X\n",
    "    data_X.append([chars_int[char] for char in seq_in])\n",
    "    # Store targets in data_y\n",
    "    data_y.append(chars_int[seq_out])\n",
    "n_patterns = len(data_X)\n",
    "print( 'Total Patterns :', n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X to be suitable to go into LSTM RNN :\n",
    "X = np.reshape(data_X , (n_patterns, seq_len, 1))\n",
    "# Normalizing input data :\n",
    "X = X/ float(n_vocab)\n",
    "# One hot encode the output targets :\n",
    "y = np_utils.to_categorical(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-LSTM-improvement-{epoch:03d}-{loss:.5f}-bigger.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='loss', verbose = 1, save_best_only = True, mode ='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_layer_num = 4 # number of LSTM layers\n",
    "layer_size = [10,10,10,10] # number of nodes in each layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(layer_size[0], input_shape =(X.shape[1], X.shape[2]), return_sequences = True))\n",
    "for i in range(1,LSTM_layer_num) :\n",
    "    model.add(LSTM(layer_size[i], return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y.shape[1]))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'epochs':30,\n",
    "                'batch_size':128,\n",
    "                'callbacks':callbacks_list,\n",
    "                'verbose':1,\n",
    "                'validation_split':0.2,\n",
    "                'validation_data':None,\n",
    "                'shuffle': True,\n",
    "                'initial_epoch':0,\n",
    "                'steps_per_epoch':None,\n",
    "                'validation_steps':None}\n",
    "model.fit(X,\n",
    "          y,\n",
    "          epochs = model_params['epochs'],\n",
    "           batch_size = model_params['batch_size'],\n",
    "           callbacks= model_params['callbacks'],\n",
    "           verbose = model_params['verbose'],\n",
    "           validation_split = model_params['validation_split'],\n",
    "           validation_data = model_params['validation_data'],\n",
    "           shuffle = model_params['shuffle'],\n",
    "           initial_epoch = model_params['initial_epoch'],\n",
    "           steps_per_epoch = model_params['steps_per_epoch'],\n",
    "           validation_steps = model_params['validation_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
